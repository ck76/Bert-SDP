"C:\Users\Takada Lab\Documents\GitHub\Bert-SDP\venv\Scripts\python.exe" "C:\Users\Takada Lab\Documents\GitHub\Bert-SDP\run.py"
bert_CNN_BiLSTM_Without_Com_squeeze
Loading data...
292it [00:02, 118.30it/s]
230it [00:01, 144.31it/s]
269it [00:01, 141.44it/s]
Time usage: 0:00:06
Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): BertLayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))
  (lstm): LSTM(764, 64, num_layers=2, batch_first=True, dropout=0.01, bidirectional=True)
  (convs): ModuleList(
    (0): Conv2d(1, 512, kernel_size=(5, 768), stride=(1, 1))
    (1): Conv2d(1, 512, kernel_size=(5, 768), stride=(1, 1))
  )
  (dropout): Dropout(p=0.01, inplace=False)
  (fc_cnn): Linear(in_features=128, out_features=3, bias=True)
  (maxpool): MaxPool1d(kernel_size=508, stride=508, padding=0, dilation=1, ceil_mode=False)
)
Epoch [1/2]
0-------4
hhhhh
(tensor([[  101,  7305,  8916,  ...,     0,     0,     0],
        [  101,  7305,  8916,  ...,  4487,  2093,   113],
        [  101,  7305,  8916,  ...,  2047, 16442,  1162],
        ...,
        [  101,  7305,  8916,  ...,   134,   121,   132],
        [  101,  7305,  8916,  ...,  3202,  2176,   113],
        [  101,  7305,  8916,  ..., 27250,  1204,  1775]], device='cuda:0'), tensor([200, 512, 512, 512, 512, 512, 508, 512, 512, 512, 512, 512, 512, 512,
        512, 512, 212, 512, 120, 512, 512, 512,  90, 512, 270, 512, 512, 164,
        169, 512, 512, 512, 512, 512, 295, 512, 512, 512, 512, 512, 512, 512,
        490, 512, 512, 512,  88, 512, 512, 512, 512, 512, 512, 512, 512, 512,
        512, 512, 512, 164, 512, 512, 512, 512], device='cuda:0'), tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'))
hhhhh-0:torch.Size([64, 512])
tensor([[  101,  7305,  8916,  ...,     0,     0,     0],
        [  101,  7305,  8916,  ...,  4487,  2093,   113],
        [  101,  7305,  8916,  ...,  2047, 16442,  1162],
        ...,
        [  101,  7305,  8916,  ...,   134,   121,   132],
        [  101,  7305,  8916,  ...,  3202,  2176,   113],
        [  101,  7305,  8916,  ..., 27250,  1204,  1775]], device='cuda:0')
hhhhh-1:torch.Size([64])
tensor([200, 512, 512, 512, 512, 512, 508, 512, 512, 512, 512, 512, 512, 512,
        512, 512, 212, 512, 120, 512, 512, 512,  90, 512, 270, 512, 512, 164,
        169, 512, 512, 512, 512, 512, 295, 512, 512, 512, 512, 512, 512, 512,
        490, 512, 512, 512,  88, 512, 512, 512, 512, 512, 512, 512, 512, 512,
        512, 512, 512, 164, 512, 512, 512, 512], device='cuda:0')
hhhhh-2:torch.Size([64, 512])
tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')
hhhhh-labels:torch.Size([64])
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
C:\Users\Takada Lab\Documents\GitHub\Bert-SDP\pytorch_pretrained\optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\torch\csrc\utils\python_arg_parser.cpp:1420.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0]
Iter:      0,  Train Loss:   1.0,  Train Acc: 50.00%,  Val Loss:  0.96,  Val Acc: 73.91%,  Time: 0:00:07 *
1-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0]
Iter:      1,  Train Loss:   1.0,  Train Acc: 50.00%,  Val Loss:  0.82,  Val Acc: 73.91%,  Time: 0:00:14 *
2-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0]
Iter:      2,  Train Loss:  0.87,  Train Acc: 50.00%,  Val Loss:  0.74,  Val Acc: 78.70%,  Time: 0:00:21 *
3-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,
        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0
 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1
 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0
 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1
 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1
 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0
 0 0 1 0 1 1 0 1]
Iter:      3,  Train Loss:  0.75,  Train Acc: 71.88%,  Val Loss:  0.71,  Val Acc: 58.70%,  Time: 0:00:28 *
Epoch [2/2]
0-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,
        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,
        1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0
 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1
 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0
 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1
 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1
 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0
 0 0 0 0 1 1 0 1]
Iter:      4,  Train Loss:   0.7,  Train Acc: 70.31%,  Val Loss:  0.67,  Val Acc: 61.30%,  Time: 0:00:35 *
1-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,
        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,
        1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0
 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1
 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0
 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1
 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0
 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0]
Iter:      5,  Train Loss:  0.66,  Train Acc: 78.12%,  Val Loss:  0.64,  Val Acc: 70.43%,  Time: 0:00:42 *
2-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,
        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,
        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 0
 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1
 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0
 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1
 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0
 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0]
Iter:      6,  Train Loss:  0.64,  Train Acc: 82.81%,  Val Loss:  0.63,  Val Acc: 67.83%,  Time: 0:00:48 *
3-------4
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
训练集：
tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,
        0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,
        0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([38, 512, 768])
torch.Size([38, 1, 512, 768])
torch.Size([38, 1, 508, 764])
torch.Size([38, 508, 764])
torch.Size([38, 508, 128])
torch.Size([38, 128, 508])
torch.Size([38, 128, 1])
torch.Size([38, 128])
测试dev集：
[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0
 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0]
[1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 0
 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1
 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0
 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1
 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0
 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1]
Iter:      7,  Train Loss:  0.61,  Train Acc: 82.81%,  Val Loss:  0.63,  Val Acc: 63.91%,  Time: 0:00:57 *
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([64, 512, 768])
torch.Size([64, 1, 512, 768])
torch.Size([64, 1, 508, 764])
torch.Size([64, 508, 764])
torch.Size([64, 508, 128])
torch.Size([64, 128, 508])
torch.Size([64, 128, 1])
torch.Size([64, 128])
torch.Size([13, 512, 768])
torch.Size([13, 1, 512, 768])
torch.Size([13, 1, 508, 764])
torch.Size([13, 508, 764])
torch.Size([13, 508, 128])
torch.Size([13, 128, 508])
torch.Size([13, 128, 1])
torch.Size([13, 128])
验证test集：
[1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1
 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0
 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1
 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0
 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1
 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 1 0 0 1]
[0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1
 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0
 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0
 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0
 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0
 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1
 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1
 1 1 0 1 0 0 1 0 0 1]
Test Loss:  0.61,  Test Acc: 69.89%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       clean     0.8148    0.7213    0.7652       183
       buggy     0.5234    0.6512    0.5803        86

    accuracy                         0.6989       269
   macro avg     0.6691    0.6862    0.6728       269
weighted avg     0.7216    0.6989    0.7061       269

Confusion Matrix...
[[132  51]
 [ 30  56]]
Time usage: 0:00:05
[W CUDAGuardImpl.h:46] Warning: CUDA warning: driver shutting down (function uncheckedGetDevice)
[W CUDAGuardImpl.h:62] Warning: CUDA warning: driver shutting down (function uncheckedSetDevice)

Process finished with exit code 0
