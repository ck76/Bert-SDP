二分类数据集全部预测到了同一类

二分类数据集全部预测到了同一类

9284
 收藏 22
分类专栏： 代码记录 文章标签： pytorch
版权

代码记录
专栏收录该内容
4 篇文章0 订阅
订阅专栏
情况描述：
之前设置了0.1， 0.01，0.0001，0.00001的学习率，也尝试了不同的batchsize进行训练，但全数据集全部预测到了同一类。

检查步骤：
1.从权重开始检查，发现学习率为0.1的时候，第一个epoch的模型权重就已经很小很小了，目前猜测是学习率太大，导致权重降的很快，现在从0.0000001开始试。

2.和师姐的baseline代码对比，发现我没有进行RandomOverSampler。任务是2分类，数据集是不平衡的，label数量是1：3。所谓over-sampling，我们可以理解为将少的一部分样本进行重采样，使其变多。(这里重采样的方式会有很多) 比如说trainset有9924张，标签为1的有7583张，标签为0的有2341张，它会把标签为1的扩充到7583张，使得整个数据集有15166张。

3.进行了数据集平衡后，尴尬的事发生了，train accuray 和 test accuracy都为0.5，网络输出的标签都是1，说明了不是数据集样本不平衡的问题。猜测是初始化权重的问题，如果一个神经网络层的权重非常小，那么在反向传播算法就会计算出很小的梯度(因为梯度gradient是与权重成正比的)。

4.接下来查看了第1个epoch和第27个epoch模型的权重参数，发现参数是更新了的，说明模型的梯度没有消失。

5.检查图像的输入，每个batch的图像会不会是同一张图像，经检查发现图像加载没有问题。而且所有的图像也都经过了归一化处理。

总结：
试了常见的学习率后，结果仍一点都不变，一定要及时检查更新的权重、梯度。设置BN层归一化。初始化权重尽量不要太小，导致梯度消失。不平衡的数据集也要进行平衡。
————————————————
版权声明：本文为CSDN博主「KORIYN」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_42037837/article/details/105741945